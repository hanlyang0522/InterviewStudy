# 기술
## Statistics/Math
###  엔트로피(Entropy)에 대해 설명해주세요. 가능하면 정보이득(Information Gain)도요.
Entropy는 0~1 사이의 값으로 주어진 데이터 집합의 **혼잡도**를 의미하며, information gain은 전체 S에서 **어떤 속성 A에 의해 구분된 후 감소된 entropy**를 말합니다. Information gain이 클수록 구분을 잘하는 것입니다.

### 로그 함수는 어떤 경우 유용합니까? 사례를 들어 설명해주세요.
로그 함수는 **데이터의 정규성**을 높이고 분석 시 정확한 값을 위해 사용합니다. 재산보유액 등 숫자가 매우 큰 데이터에 로그를 취할 경우 데이터의 왜도와 첨도를 줄일 수 있습니다. 또한 자연로그를 취할 경우 **비선형관계를 선형**으로 만들 수 있습니다.

> 데이터 정규성: 데이터 분포가 정규분포를 따르는 것  
왜도(Skewness): 분포의 비대칭도
첨도(Kurtosis): 분포의 뾰족함 정도

### 베이즈 정리에 대해 설명해주세요.
베이즈 정리는 **데이터라는 조건이 주어졌을 때의 조건부확률을 구하는 공식**입니다. 베이즈 정리를 쓰면 데이터가 주어지기 전의 사전확률값이 데이터가 주어지면서 어떻게 변하는지 계산할 수 있습니다. 따라서 데이터가 주어지기 전에 이미 어느 정도 확률값을 예측하고 있을 때 이를 새로 수집한 데이터와 합쳐서 최종 결과에 반영할 수 있습니다.

> https://datascienceschool.net/02%20mathematics/06.06%20%EB%B2%A0%EC%9D%B4%EC%A6%88%20%EC%A0%95%EB%A6%AC.html

### 신뢰 구간(Confidence Interval;CI)의 정의는 무엇인가요?
신뢰 구간은 **내가 추출한 표본평균이 관측될만한 범위**, 모수가 실제로 포함될 것으로 예측되는 범위를 말합니다.  
신뢰 구간은 샘플링된 표본이 연구중인 모집단을 얼마나 잘 대표하는지 측정하는 방법입니다.

### 평균(mean)과 중앙값(median)중에 어떤 케이스에서 뭐를 써야할까요?
값이 한쪽으로 치우친 경우 평균도 왜곡될 가능성이 있어서 중앙값을 씁니다. 중앙값은 관측값들의 변화에 민감하지 않고, outlier에 영향받지 않습니다.

### 필요한 표본의 크기를 어떻게 계산합니까?
모집단, 신뢰구간, 신뢰도, 표준편차를 먼저 결정한 후, 이에 따라 필요한 표본의 크기를 계산합니다.  
Z-score^2 * 표준편차 * (1-표준편차) / 신뢰구간^2로 계산할 수 있으며, 일반적으로 신뢰도는 90%, 95%, 99%를, 표준편차는 0.5를 사용합니다.

## Machine Learning 
### SVM은 왜 반대로 차원을 확장시키는 방식으로 동작할까요? SVM은 왜 좋을까요?
Support Vector Machine(SVM)은 **linearly separable한 데이터에 대해서만 작용**합니다. 하지만 실제 데이터는 non-linearly separable, 즉 비선형 SVM이 많습니다. 이러한 **비선형 SVM은 확장**을 통해 SVM으로 만들어줍니다. 데이터를 비선형 매핑(Mapping)을 통해 **고차원으로 변환하기 때문에 데이터를 효과적으로 표현하는 패턴**을 찾아낼 수 있습니다. SVM은 복잡한 비선형 의사결정 영역을 모형화 할 수 있기 때문에 매우 정확하며, 다른 모델보다 overfitting되는 경향이 적습니다.


###  ROC 커브에 대해 설명해주실 수 있으신가요?
이진분류기에서 true positive rate와 false positive rate의 비율로 그래프를 그린 것으로, ROC 커브가 좌상단에 붙어있을수록 더 좋은 분류기를 의미합니다.

### 회귀 / 분류시 알맞은 손실함수와 이에 대한 설명
회귀에 사용되는 손실함수로는 MAE, MSE, RMSE가 있습니다. MAE는 오차의 절댓값의 평균을 사용해 모든 오차가 동일한 가중치를 부여받아 outlier에 robust하다는 장점이 있습니다. MSE는 오차의 제곱의 평균을 사용하고 이에 루트를 씌우면 RMSE가 됩니다.
분류에 사용되는 손실함수는 Cross entropy가 있습니다. Cross entropy는 실제 분포 q를 알지 못하는 상태에서, 모델링을 통해 구한 분포인 p를 통해 q를 예측합니다.

### 최적화 기법중 Newton’s Method와 Gradient Descent 방법에 대해 알고 있나요?
Newton's method는 **방정식 f(x)=0의 해를 근사적으로** 찾는 기법입니다. **초기값에서의 접선이 x축과 닿는 지점으로 x를 업데이트**하고, 그 지점에서 다시 접선을 구한 뒤 이를 반복합니다. 초기값에 따라 수렴하는 해나 수렴 속도가 달라진다는 한계점이 있습니다.
Gradient Descent는 **f'(x) = 0**이 되는 점을 찾는 기법입니다. 초기값에서 출발해 **미분값이 0에 가까워지는 방향으로 값을 업데이트** 합니다.

### 머신러닝(machine)적 접근방법과 통계(statistics)적 접근방법의 둘간에 차이에 대한 견해가 있나요?
머신러닝은 예측의 **성공확률**을 높이는게 목적이고, 통계는 예측의 **신뢰도**를 중요하게 여깁니다.

> - 머신러닝 방법은 예측의 성공 확률을 높이는 데에 목적, 따라서 모델의 신뢰도나 정교한 가정은 상대적으로 중요성이 낮아지며, 오버피팅은 어느 정도 감안하더라도 여러 인자를 사용해 예측을 수행한다.
> - 전통적 통계분석 방법은 정해진 분포나 가정을 통해 실패 확률을 줄이는 데에 목적, 따라서 모형의 복잡성보다는 단순성을 추구하며, 신뢰도가 중요해진다. 해석 중점

## Deep Learning 
### Weight Initialization 방법에 대해 말해주세요. 그리고 무엇을 많이 사용하나요?
**Gaussian sampling**을 하거나, 이전 node 수에 영향을 받는 **LeCun init**, 다음 node 수에도 영향을 받고 uniform/normal 분포를 따르는 **Xavier init, He init** 등이 있습니다.  
Activation function이 sigmoid, tanh일 경우 Xavier init을, ReLU일 경우 He init을 사용합니다.

### 알고있는 Activation Function에 대해 알려주세요. (Sigmoid, ReLU, LeakyReLU, Tanh 등)
**Sigmoid**는 **입력을 0 ~ 1 사이로 mapping**합니다. 하지만 입력값이 커질수록 미분값이 0에 수렴해 **gradient vanishing** 문제가 생기며 **zero-centered하지 않아** 학습이 느려집니다.  
**Tanh**는 sigmoid를 변형한 쌍곡선함수로, **zero-center 문제는 해결**했지만 gradient vanishing 문제는 해결하지 못했습니다.  
**ReLU**는 입력이 양수일 경우 **saturate 문제가 해결**되며, 단순히 max 함수를 사용해 **속도가 빠릅니다**. 입력이 음수일 경우에도 saturate 문제를 해결한 함수로는 **LeakyReLU**가 있습니다.  
분류 문제에는 **softmax**를 사용하기도 합니다.

### pytorch의 dataloader에서 GPU가 어떻게 사용되는가?
batch_size와 num_worker를 조정해 배치의 크기와 병렬처리에 사용될 subprocess의 수를 조정할 수 있습니다.

> https://89douner.tistory.com/287

### 하이퍼 파라미터는 무엇인가요?
Learning rate나 SVM에서의 C, sigma 값, KNN에서의 K값 등 모델링할 때 **데이터에서 추정될 수 없는, 사용자가 직접 세팅해주는 값**을 말합니다.

### 미니배치를 작게 할때의 장단점은?
배치 사이즈를 작게 할 경우 **메모리량을 줄일 수 있습니다**. 또한 부정확한 기울기를 사용한다는 단점이 있긴 하지만, 한번 epoch 할 동안 여러번의 업데이트를 수행할 수 있고, 기울기의 부정확성이 랜덤성으로 작용해 기울기가 낮은 구간이나 **local minima에서 쉽게 벗어날 수 있습니다**.

## Operating System 
### 캐시의 지역성에 대해 설명해주세요.
프로그램은 모든 코드나 데이터를 균등하게 access하지 않는다는 특성을 전제로, 기억 장치 내의 정보를 균일하게 access하는게 아니라 **어느 한 순간에 특정 부분을 집중적으로 참조**하는 것을 말합니다.  
최근에 참조된 주소의 내용은 곧 다음에 다시 참조되는 특성인 **시간 지역성**과 대부분의 실제 프로그램이 참조된 주소와 인접한 주소의 내용이 다시 참조되는 특성인 **공간 지역성**이 있습니다.


---
# 인성
### 비 IT 동료와 효과적으로 의사소통하려면 어떻게 할지 말해주세요?
전문용어나 지식이 필요한 대화일 경우 쉽게 풀어 설명하거나 이에 대한 정보를 먼저 제공

### 이상적인 개발 환경이란 무엇이라고 생각하시나요?
활발한 코드리뷰, 피드백이 가능한 수평적 분위기 + 자유롭게 의견을 낼 수 있는 분위기 --> 성장 가능 + 프로그램 개선

### 상사와 의견차가 좁혀지지 않는 갈등이 일어났을 때 어떻게 해결할 것인가?
상사는 나보다 경험이 많음 -> 일단 믿고 수용, 하지만 나도 좋은 의견이 있을 경우엔 생각을 밝히고 의견 구함
네이버가 이런 사내생활 중 문제 생기는거 구체적 질문 많이 하더라!

### 어떤 개발자가 잘하는 개발자라고 생각하는가?
문제 인지 -> 해결책 제시 -> 프로세스 그림 -> 언어와 프레임워크로 구현 

### 간단한 1분 자기소개 부탁드려요
이름 -> 직무와 관련된 경험 + 역량 -> 포부
외운 티 내지 않기

### 최근 관심있는 분야가 있으신가요?
기업분석... 지원한 기업과 연관..?


> https://www.jobplanet.co.kr/contents/news-2705